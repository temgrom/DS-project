{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91a1c1b4-5d9a-450e-95da-8a52ccc5a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random, string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71742670-79c7-442e-b824-24fe972d71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir = \"D:/Blood/data\" # Directory with files\n",
    "train = pd.read_csv(\"train_preprocessed.csv\")\n",
    "test = pd.read_csv(\"test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b4fec00-5ea8-43b2-9243-e44d799c413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target columns\n",
    "target_columns = ['hdl_cholesterol_human', 'hemoglobin(hgb)_human', 'cholesterol_ldl_human']\n",
    "\n",
    "# Separate features and targets\n",
    "X_train = train.drop(columns=target_columns)\n",
    "X_train.drop(columns='Reading_ID', axis=1, inplace=True)\n",
    "y_train = train[target_columns]\n",
    "\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97076606-0d7c-4ae4-b144-46a56ebeb1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoders = {}\n",
    "for col in target_columns:\n",
    "    encoder = LabelEncoder()\n",
    "    y_train[col] = encoder.fit_transform(y_train[col])\n",
    "    encoders[col] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "258b1e7d-3689-44a2-ad9b-41797b456844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information between hdl_cholesterol_human and hemoglobin(hgb)_human: 0.01\n",
      "Mutual Information between hdl_cholesterol_human and cholesterol_ldl_human: 0.01\n",
      "Mutual Information between hemoglobin(hgb)_human and cholesterol_ldl_human: 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Calculate MI for each pair of targets\n",
    "for i in range(len(target_columns)):\n",
    "    for j in range(i + 1, len(target_columns)):\n",
    "        mi = mutual_info_score(y_train[target_columns[i]], y_train[target_columns[j]])\n",
    "        print(f\"Mutual Information between {target_columns[i]} and {target_columns[j]}: {mi:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e4d0132-fcc1-4d64-9d85-ef6d3b2be4c0",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a432a98c-8b9c-4f35-80f1-026c6ee68b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mRMR selected features from JSON\n",
    "with open(\"selected_features.json\", \"r\") as file:\n",
    "    selected_features = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88332e0e-c299-44e0-82de-4e19f4cda6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply selected features to train and test data\n",
    "X_train_target1 = X_train[selected_features[\"Target1\"]]\n",
    "X_train_target2 = X_train[selected_features[\"Target2\"]]\n",
    "X_train_target3 = X_train[selected_features[\"Target3\"]]\n",
    "\n",
    "X_test_target1 = X_test[selected_features[\"Target1\"]]\n",
    "X_test_target2 = X_test[selected_features[\"Target2\"]]\n",
    "X_test_target3 = X_test[selected_features[\"Target3\"]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f13faf85-53b4-4d9b-9214-acb46deef368",
   "metadata": {},
   "source": [
    "Baseline modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69e79143-a18e-47ca-8798-556fc035c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Map targets to their respective datasets\n",
    "target_to_dataset = {\n",
    "    \"hdl_cholesterol_human\": X_train_target1,\n",
    "    \"hemoglobin(hgb)_human\": X_train_target2,\n",
    "    \"cholesterol_ldl_human\": X_train_target3,\n",
    "}\n",
    "\n",
    "# Redo Stratified K-Fold for each target\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store splits for each target\n",
    "splits = {}\n",
    "\n",
    "# Process each target\n",
    "for target, X_target in target_to_dataset.items():\n",
    "    \n",
    "    # Get the corresponding labels\n",
    "    y_target = y_train[target]\n",
    "    \n",
    "    # Compute Stratified K-Fold splits\n",
    "    splits[target] = list(skf.split(X_target, y_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "182948a8-0d7c-4ec5-84cf-d203432eb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Models for Target: hdl_cholesterol_human ===\n",
      "  Fold 1: Accuracy = 0.6499\n",
      "  Fold 2: Accuracy = 0.6663\n",
      "  Fold 3: Accuracy = 0.6545\n",
      "  Fold 4: Accuracy = 0.6495\n",
      "  Fold 5: Accuracy = 0.6454\n",
      "\n",
      "=== Training Models for Target: hemoglobin(hgb)_human ===\n",
      "  Fold 1: Accuracy = 0.9041\n",
      "  Fold 2: Accuracy = 0.9053\n",
      "  Fold 3: Accuracy = 0.9026\n",
      "  Fold 4: Accuracy = 0.9026\n",
      "  Fold 5: Accuracy = 0.9041\n",
      "\n",
      "=== Training Models for Target: cholesterol_ldl_human ===\n",
      "  Fold 1: Accuracy = 0.6762\n",
      "  Fold 2: Accuracy = 0.6629\n",
      "  Fold 3: Accuracy = 0.6659\n",
      "  Fold 4: Accuracy = 0.6705\n",
      "  Fold 5: Accuracy = 0.6739\n",
      "\n",
      "hdl_cholesterol_human Average Accuracy: 0.6531\n",
      "\n",
      "hemoglobin(hgb)_human Average Accuracy: 0.9037\n",
      "\n",
      "cholesterol_ldl_human Average Accuracy: 0.6699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "baseline_model = RandomForestClassifier(max_depth=15, min_samples_leaf=10,\n",
    "                                       min_samples_split=15, n_estimators=160,\n",
    "                                       random_state=42)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for target, fold_splits in splits.items():\n",
    "    print(f\"\\n=== Training Models for Target: {target} ===\")\n",
    "\n",
    "    # Access target-specific dataset and labels\n",
    "    X_target = target_to_dataset[target]\n",
    "    y_target = y_train[target]\n",
    "\n",
    "    results[target] = []\n",
    "\n",
    "    # Iterate through folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(fold_splits):\n",
    "        # Split the data\n",
    "        X_train_fold = X_target.iloc[train_idx]\n",
    "        X_val_fold = X_target.iloc[val_idx]\n",
    "        y_train_fold = y_target.iloc[train_idx]\n",
    "        y_val_fold = y_target.iloc[val_idx]\n",
    "\n",
    "        # Train the model\n",
    "        model = baseline_model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Validate the model\n",
    "        y_val_pred = model.predict(X_val_fold)\n",
    "        accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "        print(f\"  Fold {fold + 1}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "        # Store fold results\n",
    "        results[target].append(accuracy)\n",
    "\n",
    "# Summary of results\n",
    "for target, accuracies in results.items():\n",
    "    print(f\"\\n{target} Average Accuracy: {sum(accuracies) / len(accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f15389-b67f-414a-9618-b8c2b8730b16",
   "metadata": {},
   "source": [
    "Hyperopt for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7c4d477-a252-4dc5-9359-53d43265996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Objective function\n",
    "def objective(params):\n",
    "    # Unpack hyperparameters\n",
    "    n_estimators = int(params[\"n_estimators\"])\n",
    "    max_depth = int(params[\"max_depth\"])\n",
    "    min_samples_split = int(params[\"min_samples_split\"])\n",
    "    min_samples_leaf = int(params[\"min_samples_leaf\"])\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    accuracy = cross_val_score(model, X_train, y_train.iloc[:,0], cv=5, scoring=\"accuracy\").mean()\n",
    "\n",
    "    # Return negative accuracy (because Hyperopt minimizes)\n",
    "    return {\"loss\": -accuracy, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b223dd9-b2b1-4ef4-9b04-b26477c270a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter space\n",
    "search_space = {\n",
    "    \"n_estimators\": hp.quniform(\"n_estimators\", 50, 300, 10),  \n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 5, 50, 5),          \n",
    "    \"min_samples_split\": hp.quniform(\"min_samples_split\", 2, 20, 1),  \n",
    "    \"min_samples_leaf\": hp.quniform(\"min_samples_leaf\", 1, 10, 1)      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc6564e6-0383-49b7-a27b-3c1872fd3e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 10/10 [22:56<00:00, 137.60s/trial, best loss: -0.5928462709284628]\n",
      "Best Hyperparameters: {'max_depth': 30.0, 'min_samples_leaf': 1.0, 'min_samples_split': 16.0, 'n_estimators': 230.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_params = fmin(\n",
    "    fn=objective,                \n",
    "    space=search_space,          \n",
    "    algo=tpe.suggest,            # Tree of Parzen Estimators (TPE) algorithm\n",
    "    max_evals=10,                \n",
    "    trials=trials,              \n",
    "    rstate=np.random.default_rng(42)  \n",
    ")\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b614ea2-d02c-4a8e-8a8d-4e6c3dc64e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert best_params to integers (if necessary)\n",
    "best_params = {\n",
    "    \"n_estimators\": int(best_params[\"n_estimators\"]),\n",
    "    \"max_depth\": int(best_params[\"max_depth\"]),\n",
    "    \"min_samples_split\": int(best_params[\"min_samples_split\"]),\n",
    "    \"min_samples_leaf\": int(best_params[\"min_samples_leaf\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8012505-d57f-48c7-8d87-212d104ccd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
